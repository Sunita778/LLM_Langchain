{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78a57c3d-aa6c-4d9e-ab09-e2c05dbb673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import langchain\n",
    "import pinecone\n",
    "# from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain.embedding.openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain.vectorstores import pinecone\n",
    "from langchain_pinecone import Pinecone\n",
    "from langchain_openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74cbc90d-895d-4c13-8352-f8fcc3e55c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "402d1180-9793-42ee-9d7c-56e08e5b9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_doc(directory):\n",
    "#     file_loader = PyPDFLoader(directory)\n",
    "#     documents = file_loader.load()\n",
    "#     return documents\n",
    "\n",
    "def read_doc(directory):\n",
    "    # 1. Use the DirectoryLoader\n",
    "    file_loader = DirectoryLoader(\n",
    "        path=directory,             # The directory you pass in\n",
    "        glob=\"**/*.pdf\",            # Look for all files ending in .pdf\n",
    "        loader_cls=PyPDFLoader      # Use PyPDFLoader for each PDF file found\n",
    "    )\n",
    "    \n",
    "    # 2. Load all documents found in the directory\n",
    "    documents = file_loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86a8177b-14cd-4ba1-9df5-dd83d7c45bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = read_doc(\"C:/Users/sunit/Sunita/SG/RAG/LLM_Lanchain/documents/\")\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f1341fe-aece-4e33-ab71-d99e92f7199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the docs into chunks\n",
    "def chunk_data(docs,chunk_size=800,chunk_overlap=50):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    doc=text_splitter.split_documents(docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfaee548-e11d-46b0-8f42-d6c3e0758567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = chunk_data(docs = doc)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260be6a1-882b-4531-a002-1369e7889f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding technique of OpenAI\n",
    "embedding = OpenAIEmbeddings(api_key=os.environ[\"OPEN_API_KEY\"])\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d510f-0672-4a5d-889e-81abe9c189e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = embedding.embed_query(\"How are you?\")\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859bac1-8d77-44a1-93b7-57870900472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectore Search DB in Pinecone\n",
    "pinecone.init(\n",
    "    api+key = \"jhdshsjjsksks\"\n",
    "    environment = \"gcp-starter\"\n",
    ")\n",
    "\n",
    "index_name = \"langchainvector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09189d-244a-46d7-8f33-7e2757bd1a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = Pinecone.from_documents(doc, embedding, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88745491-3ff0-409b-96eb-63feb961e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity Retrive from VectoerDB\n",
    "def retrive_query(query, k=2):\n",
    "    matching_results = index.similarity_search(query, k=k)\n",
    "    return matching_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f1db37-14d3-48e3-aa6d-cd060cce360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ab0bf-077b-420b-b547-797fcf2b4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0.5)\n",
    "chain = load_qa_chain(llm, chain_type = \"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8af52-fc5c-4a9e-85ec-7fcf9fa59094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search answer from vectorDB\n",
    "def retrive_answers(query):\n",
    "    doc_search = retrive_query(query)\n",
    "    print(doc_search)\n",
    "\n",
    "    response = chain.run(input_documents= doc_search, question = query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3316620-0d4b-4e48-982d-415f9caabce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_query = \"Explain the use of vector database\"\n",
    "answer = retrive_answers(our_query)\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
